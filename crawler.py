import logging
import time
import json
import os
import re
from typing import Dict, List, Optional
from api_client_enhanced import TikTokAPIClientEnhanced
from data_processor import DataProcessor


class TikTokCrawler:
    """TikTokçˆ¬è™«ä¸»ç±»"""

    def __init__(self, use_selenium: bool = None):
        self.api_client = TikTokAPIClientEnhanced(use_selenium=use_selenium)
        self.data_processor = DataProcessor()
        self.logger = logging.getLogger(__name__)

    def crawl_search_preview(self, keyword: str) -> Optional[str]:
        """
        çˆ¬å–æœç´¢é¢„è§ˆæ¥å£

        Args:
            keyword: æœç´¢å…³é”®è¯

        Returns:
            ä¿å­˜çš„Excelæ–‡ä»¶è·¯å¾„æˆ–None
        """
        try:
            self.logger.info(f"ğŸ“ ä»»åŠ¡å¼€å§‹ - å…³é”®è¯: {keyword}")

            # é¦–å…ˆå°è¯•APIè¯·æ±‚
            self.logger.info("ğŸŒ å°è¯•APIç›´æ¥è¯·æ±‚...")
            response_data = self.api_client.make_request(
                api_name='search_general_preview',
                dynamic_params={'keyword': keyword}
            )

            # å¦‚æœAPIè¯·æ±‚å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨Seleniumç›´æ¥è·å–æ•°æ®
            if response_data is None and self.api_client.use_selenium:
                self.logger.info("ğŸ¤– APIè¯·æ±‚å¤±è´¥ï¼Œå¯ç”¨Seleniumæ¨¡å¼...")
                response_data = self._crawl_with_selenium_direct(keyword)

            if response_data is None:
                self.logger.error(f"âŒ æ•°æ®è·å–å¤±è´¥ - å…³é”®è¯: {keyword}")
                return None

            # ç»Ÿè®¡è·å–çš„æ•°æ®é‡
            data_count = 0
            if isinstance(response_data, dict):
                if 'sug_list' in response_data:
                    data_count = len(response_data['sug_list'])
                elif 'search_results' in response_data:
                    data_count = len(response_data['search_results'])
                elif isinstance(response_data.get('data'), list):
                    data_count = len(response_data['data'])

            self.logger.info(f"ğŸ“Š æ•°æ®è·å–æˆåŠŸ - å…± {data_count} æ¡è®°å½•")

            # ä¿å­˜ä¸ºExcel
            self.logger.info("ğŸ’¾ å¼€å§‹ä¿å­˜Excelæ–‡ä»¶...")
            excel_path = self.data_processor.save_to_excel(
                data=response_data,
                api_name='search_preview',
                keyword=keyword
            )

            self.logger.info(f"âœ… æ–‡ä»¶ä¿å­˜æˆåŠŸ: {os.path.basename(excel_path)}")
            return excel_path

        except Exception as e:
            self.logger.error(f"ğŸ’¥ çˆ¬å–å¼‚å¸¸ - å…³é”®è¯: {keyword}, é”™è¯¯: {str(e)}")
            return None

    def _crawl_with_selenium_direct(self, keyword: str) -> Optional[Dict]:
        """
        ä½¿ç”¨Seleniumç›´æ¥ä»é¡µé¢è·å–æ•°æ®

        Args:
            keyword: æœç´¢å…³é”®è¯

        Returns:
            æå–çš„æ•°æ®æˆ–None
        """
        try:
            if not self.api_client.driver:
                self.logger.error("ğŸ¤– Seleniumé©±åŠ¨æœªåˆå§‹åŒ–")
                return None

            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from urllib.parse import quote

            # æ„å»ºæœç´¢URL
            encoded_keyword = quote(keyword)
            search_url = f"https://www.tiktok.com/search?q={encoded_keyword}"

            self.logger.info(f"ğŸŒ è®¿é—®æœç´¢é¡µé¢: {search_url}")
            self.api_client.driver.get(search_url)

            self.logger.info("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
            time.sleep(5)

            # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
            try:
                WebDriverWait(self.api_client.driver, 10).until(
                    EC.presence_of_element_located(
                        (By.CSS_SELECTOR, "[data-e2e='search-card-item'], [data-e2e='search-video-item']"))
                )
            except:
                self.logger.warning("æœç´¢ç»“æœæœªåŠ è½½å®Œæˆï¼Œç»§ç»­å°è¯•æå–æ•°æ®")

            self.logger.info("ğŸ” å°è¯•æ‹¦æˆªç½‘ç»œè¯·æ±‚...")
            response_data = self._intercept_network_requests()

            if response_data:
                self.logger.info("âœ… ç½‘ç»œè¯·æ±‚æ‹¦æˆªæˆåŠŸ")
                return response_data

            self.logger.info("ğŸ”§ ç½‘ç»œæ‹¦æˆªå¤±è´¥ï¼Œå°è¯•é¡µé¢å…ƒç´ æå–...")
            return self._extract_data_from_page_elements(keyword)

        except Exception as e:
            self.logger.error(f"ğŸ¤– Seleniumæ•°æ®è·å–å¤±è´¥: {str(e)}")
            return None

    def _intercept_network_requests(self) -> Optional[Dict]:
        """
        ä»æµè§ˆå™¨ç½‘ç»œè¯·æ±‚ä¸­æ‹¦æˆªAPIå“åº”

        Returns:
            æ‹¦æˆªåˆ°çš„APIå“åº”æ•°æ®æˆ–None
        """
        try:
            # è·å–æµè§ˆå™¨æ—¥å¿—
            logs = self.api_client.driver.get_log('performance')

            api_responses = []

            for log in logs:
                try:
                    message = json.loads(log['message'])
                    if message['message']['method'] == 'Network.responseReceived':
                        url = message['message']['params']['response']['url']
                        # æ£€æŸ¥å¤šç§å¯èƒ½çš„APIè·¯å¾„
                        if any(api_path in url for api_path in [
                            '/api/search/general/preview/',
                            '/api/search/item/',
                            '/api/search/',
                            '/api/recommend/',
                            'search'
                        ]):
                            request_id = message['message']['params']['requestId']

                            # å°è¯•è·å–å“åº”ä½“
                            try:
                                response_body = self.api_client.driver.execute_cdp_cmd(
                                    'Network.getResponseBody',
                                    {'requestId': request_id}
                                )

                                if response_body and 'body' in response_body:
                                    body_data = json.loads(
                                        response_body['body'])
                                    api_responses.append({
                                        'url': url,
                                        'data': body_data
                                    })
                                    self.logger.info(f"æˆåŠŸæ‹¦æˆªAPIå“åº”: {url}")

                            except Exception as e:
                                self.logger.debug(f"è·å–å“åº”ä½“å¤±è´¥ {url}: {str(e)}")
                                continue
                except Exception as e:
                    self.logger.debug(f"è§£ææ—¥å¿—å¤±è´¥: {str(e)}")
                    continue

            # è¿”å›æœ€ç›¸å…³çš„APIå“åº”
            if api_responses:
                # ä¼˜å…ˆè¿”å›search/general/previewçš„å“åº”
                for response in api_responses:
                    if '/api/search/general/preview/' in response['url']:
                        return response['data']

                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€ä¸ªåŒ…å«æ•°æ®çš„å“åº”
                for response in api_responses:
                    if response['data']:
                        return response['data']

            return None

        except Exception as e:
            self.logger.debug(f"ç½‘ç»œè¯·æ±‚æ‹¦æˆªå¤±è´¥: {str(e)}")
            return None

    def _extract_data_from_page_elements(self, keyword: str) -> Optional[Dict]:
        """ä»é¡µé¢å…ƒç´ ä¸­æå–æ•°æ®

        Args:
            keyword: æœç´¢å…³é”®è¯

        Returns:
            æå–çš„æ•°æ®å­—å…¸æˆ–None
        """
        try:
            from selenium.webdriver.common.by import By

            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            time.sleep(3)

            # å°è¯•å¤šç§é€‰æ‹©å™¨æ¥æŸ¥æ‰¾è§†é¢‘å…ƒç´ 
            selectors = [
                "[data-e2e='search-card-item']",
                "[data-e2e='search-video-item']",
                "[data-e2e*='search']",
                "div[class*='DivItemContainer']",
                "div[class*='video']",
                "a[href*='/video/']",
                "div[data-e2e]",
                ".tiktok-yz6ijl-DivWrapper",
                ".tiktok-x6y88p-DivItemContainerV2"
            ]

            video_elements = []
            for selector in selectors:
                try:
                    elements = self.api_client.driver.find_elements(
                        By.CSS_SELECTOR, selector)
                    if elements:
                        video_elements = elements
                        self.logger.info(
                            f"ä½¿ç”¨é€‰æ‹©å™¨æ‰¾åˆ°å…ƒç´ : {selector} ({len(elements)}ä¸ª)")
                        break
                except Exception as e:
                    self.logger.debug(f"é€‰æ‹©å™¨å¤±è´¥ {selector}: {str(e)}")
                    continue

            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰åŒ…å«é“¾æ¥çš„div
            if not video_elements:
                try:
                    all_divs = self.api_client.driver.find_elements(
                        By.TAG_NAME, "div")
                    video_elements = [
                        div for div in all_divs if div.find_elements(By.TAG_NAME, "a")]
                    self.logger.info(f"é€šè¿‡div+aæŸ¥æ‰¾åˆ° {len(video_elements)} ä¸ªæ½œåœ¨å…ƒç´ ")
                except Exception as e:
                    self.logger.debug(f"å¤‡ç”¨æŸ¥æ‰¾å¤±è´¥: {str(e)}")

            extracted_data = {
                'keyword': keyword,
                'search_results': [],
                'total_count': len(video_elements),
                'extraction_method': 'selenium_page_elements',
                'timestamp': int(time.time()),
                'page_url': self.api_client.driver.current_url,
                'page_title': self.api_client.driver.title
            }

            self.logger.info(f"ğŸ¯ æ‰¾åˆ° {len(video_elements)} ä¸ªé¡µé¢å…ƒç´ ")

            # ä¿å­˜é¡µé¢æˆªå›¾ç”¨äºè°ƒè¯•
            try:
                screenshot_path = f"debug_responses/page_screenshot_{int(time.time())}.png"
                self.api_client.driver.save_screenshot(screenshot_path)
                self.logger.debug(f"é¡µé¢æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            except Exception as e:
                self.logger.debug(f"ä¿å­˜æˆªå›¾å¤±è´¥: {str(e)}")

            for i, element in enumerate(video_elements[:20]):  # é™åˆ¶æå–å‰20ä¸ª
                try:
                    # æ»šåŠ¨åˆ°å…ƒç´ å¯è§åŒºåŸŸ
                    try:
                        self.api_client.driver.execute_script(
                            "arguments[0].scrollIntoView(true);", element)
                        time.sleep(0.1)
                    except:
                        pass

                    # åŸºæœ¬å…ƒç´ ä¿¡æ¯
                    video_data = {
                        'index': i,
                        'element_text': element.text.strip()[:500] if element.text else '',
                        'element_tag': element.tag_name,
                        'element_class': element.get_attribute('class') or '',
                        'data_e2e': element.get_attribute('data-e2e') or '',
                        'element_id': element.get_attribute('id') or '',
                    }

                    # å°è¯•æå–é“¾æ¥
                    try:
                        link_elements = element.find_elements(By.TAG_NAME, 'a')
                        if link_elements:
                            href = link_elements[0].get_attribute('href')
                            if href and 'tiktok.com' in href:
                                video_data['video_url'] = href
                    except:
                        pass

                    # å°è¯•æå–å›¾ç‰‡
                    try:
                        img_elements = element.find_elements(
                            By.TAG_NAME, 'img')
                        if img_elements:
                            src = img_elements[0].get_attribute('src')
                            if src:
                                video_data['thumbnail_url'] = src
                    except:
                        pass

                    # å°è¯•æå–æ ‡é¢˜å’Œæè¿°
                    try:
                        # æŸ¥æ‰¾æ ‡é¢˜å…ƒç´ 
                        title_selectors = [
                            'h1', 'h2', 'h3', '[data-e2e*="title"]', 'strong', '.title']
                        for selector in title_selectors:
                            try:
                                title_elements = element.find_elements(
                                    By.CSS_SELECTOR, selector)
                                if title_elements and title_elements[0].text.strip():
                                    video_data['title'] = title_elements[0].text.strip(
                                    )
                                    break
                            except:
                                continue
                    except:
                        pass

                    # åªä¿å­˜æœ‰ç”¨çš„æ•°æ®
                    if (video_data.get('video_url') or
                        video_data.get('element_text') or
                            video_data.get('title')):
                        extracted_data['search_results'].append(video_data)

                except Exception as e:
                    self.logger.debug(f"æå–ç¬¬{i}ä¸ªå…ƒç´ æ•°æ®å¤±è´¥: {str(e)}")
                    continue

            # å¦‚æœæ²¡æœ‰æå–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œå°è¯•è·å–é¡µé¢æºç ä¸­çš„ç»“æ„åŒ–æ•°æ®
            if not extracted_data['search_results']:
                try:
                    page_source = self.api_client.driver.page_source
                    # æŸ¥æ‰¾å¯èƒ½çš„JSONæ•°æ®
                    json_matches = re.findall(
                        r'\{[^{}]*"id"[^{}]*\}', page_source)
                    if json_matches:
                        # ä¿å­˜å‰5ä¸ªåŒ¹é…é¡¹
                        extracted_data['raw_json_data'] = json_matches[:5]
                        self.logger.info(
                            f"ä»é¡µé¢æºç ä¸­æå–åˆ° {len(json_matches)} ä¸ªJSONç‰‡æ®µ")
                except Exception as e:
                    self.logger.debug(f"æå–é¡µé¢JSONå¤±è´¥: {str(e)}")

            if extracted_data['search_results'] or extracted_data.get('raw_json_data'):
                self.logger.info(
                    f"ğŸ“‹ æˆåŠŸæå– {len(extracted_data['search_results'])} æ¡ç»“æ„åŒ–æ•°æ®")
                return extracted_data
            else:
                self.logger.warning("âš ï¸  æœªèƒ½æå–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¿”å›é¡µé¢åŸºæœ¬ä¿¡æ¯")
                # è¿”å›åŸºæœ¬é¡µé¢ä¿¡æ¯
                return {
                    'keyword': keyword,
                    'extraction_method': 'page_info_only',
                    'page_url': self.api_client.driver.current_url,
                    'page_title': self.api_client.driver.title,
                    'page_text_preview': self.api_client.driver.find_element(By.TAG_NAME, "body").text[:1000],
                    'timestamp': int(time.time())
                }

        except Exception as e:
            self.logger.error(f"ğŸ“„ é¡µé¢å…ƒç´ æå–å¤±è´¥: {str(e)}")
            return None

    def crawl_multiple_keywords(self, keywords: List[str]) -> List[str]:
        """
        æ‰¹é‡çˆ¬å–å¤šä¸ªå…³é”®è¯

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨

        Returns:
            æˆåŠŸä¿å­˜çš„CSVæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        successful_files = []

        for keyword in keywords:
            try:
                csv_path = self.crawl_search_preview(keyword)
                if csv_path:
                    successful_files.append(csv_path)

                # æ·»åŠ å»¶æ—¶é¿å…è¯·æ±‚è¿‡å¿«
                import time
                time.sleep(1)

            except Exception as e:
                self.logger.error(f"å¤„ç†å…³é”®è¯ {keyword} æ—¶å‡ºé”™: {str(e)}")
                continue

        return successful_files

    def add_api_config(self, api_name: str, config: Dict):
        """
        åŠ¨æ€æ·»åŠ æ–°çš„APIé…ç½®ï¼ˆä¸ºåç»­æ‰©å±•å‡†å¤‡ï¼‰

        Args:
            api_name: APIåç§°
            config: APIé…ç½®
        """
        from config import Config
        Config.API_CONFIGS[api_name] = config
        self.logger.info(f"å·²æ·»åŠ æ–°çš„APIé…ç½®: {api_name}")

    def close(self):
        """å…³é—­çˆ¬è™«ï¼Œé‡Šæ”¾èµ„æº"""
        self.api_client.close()
